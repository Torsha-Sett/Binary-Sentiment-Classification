{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Fine-Tune-BERT-for-Text-Classification-with-TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Torsha-Sett/Binary-Sentiment-Classification/blob/main/Fine_Tune_BERT_for_Text_Classification_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGCJYkQj_Uu2"
      },
      "source": [
        "<h2 align=center> Fine-Tune BERT for Text Classification with TensorFlow</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y2m1S6e12il"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 1: BERT Classification Model</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYYYWqWr_WCC"
      },
      "source": [
        "In this [project](https://www.coursera.org/projects/fine-tune-bert-tensorflow/), you will learn how to fine-tune a BERT model for text classification using TensorFlow and TF-Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQG5PCO_WFx"
      },
      "source": [
        "The pretrained BERT model used in this project is [available](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2) on [TensorFlow Hub](https://tfhub.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pKNS21u_WJo"
      },
      "source": [
        "### Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3NHSMXv_WMv"
      },
      "source": [
        "By the time you complete this project, you will be able to:\n",
        "\n",
        "- Build TensorFlow Input Pipelines for Text Data with the [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) API\n",
        "- Tokenize and Preprocess Text for BERT\n",
        "- Fine-tune BERT for text classification with TensorFlow 2 and [TF Hub](https://tfhub.dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6BEe-3-AVRQ"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc9f-8rLAVUS"
      },
      "source": [
        "In order to be successful with this project, it is assumed you are:\n",
        "\n",
        "- Competent in the Python programming language\n",
        "- Familiar with deep learning for Natural Language Processing (NLP)\n",
        "- Familiar with TensorFlow, and its Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYXXV5n3Ab-4"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhK-SYGyAjxe"
      },
      "source": [
        "This project/notebook consists of several Tasks.\n",
        "\n",
        "- **[Task 1]()**: Introduction to the Project.\n",
        "- **[Task 2]()**: Setup your TensorFlow and Colab Runtime\n",
        "- **[Task 3]()**: Download and Import the Quora Insincere Questions Dataset\n",
        "- **[Task 4]()**: Create tf.data.Datasets for Training and Evaluation\n",
        "- **[Task 5]()**: Download a Pre-trained BERT Model from TensorFlow Hub\n",
        "- **[Task 6]()**: Tokenize and Preprocess Text for BERT\n",
        "- **[Task 7]()**: Wrap a Python Function into a TensorFlow op for Eager Execution\n",
        "- **[Task 8]()**: Create a TensorFlow Input Pipeline with `tf.data`\n",
        "- **[Task 9]()**: Add a Classification Head to the BERT `hub.KerasLayer`\n",
        "- **[Task 10]()**: Fine-Tune BERT for Text Classification\n",
        "- **[Task 11]()**: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaArqXjRAcBa"
      },
      "source": [
        "## Task 2: Setup your TensorFlow and Colab Runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDhjzZ5A4Q_"
      },
      "source": [
        "You will only be able to use the Colab Notebook after you save it to your Google Drive folder. Click on the File menu and select “Save a copy in Drive…\n",
        "\n",
        "![Copy to Drive](https://drive.google.com/uc?id=1CH3eDmuJL8WR0AP1r3UE6sOPuqq8_Wl7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpe6GhLuBJWB"
      },
      "source": [
        "### Check GPU Availability\n",
        "\n",
        "Check if your Colab notebook is configured to use Graphical Processing Units (GPUs). If zero GPUs are available, check if the Colab notebook is configured to use GPUs (Menu > Runtime > Change Runtime Type).\n",
        "\n",
        "![Hardware Accelerator Settings](https://drive.google.com/uc?id=1qrihuuMtvzXJHiRV8M7RngbxFYipXKQx)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V9c8vzSL3aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c620fef-edf8-46f1-b6da-208f6999b529"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul 29 15:57:40 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obch3rAuBVf0"
      },
      "source": [
        "### Install TensorFlow and TensorFlow Model Garden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUQEY3dFB0jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b6a5205-b204-4cde-eb3f-a90598f0262c"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU3YLZ1TYKUt"
      },
      "source": [
        "#!pip install -q tensorflow==2.3.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFRTC-zwUy6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1010e8c-0b4e-4ce8-bc09-2d1689941a91"
      },
      "source": [
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2650, done.\u001b[K\n",
            "remote: Counting objects: 100% (2650/2650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2311/2311), done.\u001b[K\n",
            "remote: Total 2650 (delta 505), reused 1389 (delta 306), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2650/2650), 34.02 MiB | 29.72 MiB/s, done.\n",
            "Resolving deltas: 100% (505/505), done.\n",
            "Note: checking out '400d68abbccda2f0f6609e3a924467718b144233'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H2G0571zLLs"
      },
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "# you may have to restart the runtime afterwards"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVjksk4yCXur"
      },
      "source": [
        "## Restart the Runtime\n",
        "\n",
        "**Note** \n",
        "After installing the required Python packages, you'll need to restart the Colab Runtime Engine (Menu > Runtime > Restart runtime...)\n",
        "\n",
        "![Restart of the Colab Runtime Engine](https://drive.google.com/uc?id=1xnjAy2sxIymKhydkqb0RKzgVK9rh3teH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMsEoT3Fg4Wg"
      },
      "source": [
        "## Task 3: Download and Import the Quora Insincere Questions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmqEylyFYTdP"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuX1lB8pPJ-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55eecd8e-a09a-4fa8-e97b-328e602a5680"
      },
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version:  2.8.2\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtbwpWgyEZg7"
      },
      "source": [
        "A downloadable copy of the [Quora Insincere Questions Classification data](https://www.kaggle.com/c/quora-insincere-questions-classification/data) can be found [https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip](https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip). Decompress and read the data into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nI-9itVwCCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122b2054-2ccf-4ff3-bd44-15704a7ebe59"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df=pd.read_csv('https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip', compression='zip', low_memory=False)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1306122, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeHE98KiMvDd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "11708d2a-b616-4bd1-f0bf-86e7fa530b24"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    qid                                      question_text  \\\n",
              "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
              "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
              "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
              "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
              "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
              "\n",
              "   target  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       0  \n",
              "4       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41957978-af88-4fa1-9869-7df1394ee181\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41957978-af88-4fa1-9869-7df1394ee181')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41957978-af88-4fa1-9869-7df1394ee181 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41957978-af88-4fa1-9869-7df1394ee181');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leRFRWJMocVa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "bc4dd4db-9ecf-49f2-fe99-de65954b71cb"
      },
      "source": [
        "df.target.plot(kind='hist', title='Target Distribution')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:title={'center':'Target Distribution'}, ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELjswHcFHfp3"
      },
      "source": [
        "## Task 4: Create tf.data.Datasets for Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fScULIGPwuWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db09331-9d84-4e32-8760-85c60e2657b0"
      },
      "source": [
        "train_df,remaining=train_test_split(df, random_state=42, train_size=0.0075, stratify=df.target.values)\n",
        "valid_df, test = train_test_split(remaining, random_state=42, train_size=0.00075, stratify=remaining.target.values)\n",
        "df.shape,train_df.shape,valid_df.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1306122, 3), (9795, 3), (972, 3), (1295355, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQYMGT5_qLPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feee0430-cf22-4bfc-bb80-40fe34950b51"
      },
      "source": [
        "#create a tf.data.dataset object which is a python iterable. we are doing this to make input data pipeline more efficient\n",
        "with tf.device('/cpu:0'):\n",
        "  train_data= tf.data.Dataset.from_tensor_slices((train_df['question_text'].values, train_df.target.values)) #creates a tf dataset for training\n",
        "  valid_data= tf.data.Dataset.from_tensor_slices((valid_df['question_text'].values, valid_df.target.values)) \n",
        "  #above retures a python iterable which can be consumed by a for loop\n",
        "  #returning first element using take\n",
        "  for text, label in train_data.take(1):\n",
        "    print(text)\n",
        "    print(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Why are unhealthy relationships so desirable?', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2-ReN88Hvy_"
      },
      "source": [
        "## Task 5: Download a Pre-trained BERT Model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMb5M86b4-BU"
      },
      "source": [
        "\"\"\"\n",
        "Each line of the dataset is composed of the review text and its label\n",
        "- Data preprocessing consists of transforming text to BERT input features:\n",
        "input_word_ids, input_mask, segment_ids\n",
        "- In the process, tokenizing the text is done with the provided BERT model tokenizer\n",
        "\"\"\"\n",
        "label_list = [0,1] # Label categories\n",
        "max_seq_len = 128 # maximum length of (token) input sequences\n",
        "train_batch_size=32\n",
        "\n",
        "\n",
        "# Get BERT layer and tokenizer:\n",
        "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2 #copy paste link in a new tab #bert pretrained model from google \n",
        "# saved in tensorflow 2 format that uses the implementation of BERT from the TF official models repository that we just downloaded earlier.\n",
        "# uses 12 hidden layers or transformer blocks with hidden size of 768. This means that it returns contexualized embeddings of 768 dimensions with 12 attention heads\n",
        "# in Computer vision we freeze some layers and fine tune others. here in BERT it is recommended to finetune all parameters\n",
        "#first tokenize input text into specific format. eg shown in link page\n",
        "\n",
        "#Get the BERT layer\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2', trainable=True)\n",
        "\n",
        "#instantiate the tokenizer which will do all the preprocessing and tokenizing for us\n",
        "#tokenizer requires 2 things 1) vocabulary file used in BERT \n",
        "vocab = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy() #just checking the BERT we imported is case sensitive version or not\n",
        "tokenizer = tokenization.FullTokenizer(vocab,do_lower_case) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEUezMK-zkkI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb620e5-7271-4b1d-cf20-7cbf76996ddd"
      },
      "source": [
        "tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing william today?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '##,', 'how', 'are', 'you', 'doing', 'william', 'today', '##?']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AFsmTO5JSmc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QinzNq6OsP1"
      },
      "source": [
        "## Task 6: Tokenize and Preprocess Text for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FTqJ698zZ1e"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1-SpKFELnEvBMBqO7h3iypo8q9uUUo96P' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 2: BERT Tokenizer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWYkggYe6HZc"
      },
      "source": [
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create InputExamples using `classifier_data_lib`'s constructor `InputExample` provided in the BERT library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-21A5aNJM0W"
      },
      "source": [
        "# This provides a function to convert row to input features and label\n",
        "#function to convert a row from our data into input features and label\n",
        "\n",
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_len, tokenizer=tokenizer):\n",
        "  example = classifier_data_lib.InputExample(guid=None, \n",
        "                                             text_a = text.numpy(),\n",
        "                                             text_b = None , #since we are not doing next sentence prediction\n",
        "                                             label = label.numpy())\n",
        "  #convert examples to features\n",
        "  feature = classifier_data_lib.convert_single_example(0,example,label_list,max_seq_len,tokenizer)\n",
        "  #above function returns feature object which is our interest\n",
        "  return(feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_HQSsHwWCsK"
      },
      "source": [
        "You want to use [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) to apply this function to each element of the dataset. [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) runs in graph mode.\n",
        "\n",
        "- Graph tensors do not have a value.\n",
        "- In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function). The [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNlkKVfWX0Q"
      },
      "source": [
        "## Task 7: Wrap a Python Function into a TensorFlow op for Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGACBcfCWC2O"
      },
      "source": [
        "def to_feature_map(text, label):\n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, inp=[text, label], \n",
        "                                                                Tout=[tf.int32, tf.int32, tf.int32, tf.int32]) #for each type of ids\n",
        "  \n",
        "  input_ids.set_shape([max_seq_len])\n",
        "  input_mask.set_shape([max_seq_len])\n",
        "  segment_ids.set_shape([max_seq_len])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  x = {\n",
        "      'input_word_ids': input_ids,\n",
        "       'input_mask': input_mask,\n",
        "       'input_type_ids':segment_ids\n",
        "  }\n",
        "\n",
        "  return(x,label_id)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhdO6MjTbtn1"
      },
      "source": [
        "## Task 8: Create a TensorFlow Input Pipeline with `tf.data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHRdiO3dnPNr"
      },
      "source": [
        "from tensorflow.python.data.ops.dataset_ops import AUTOTUNE\n",
        "from tensorflow._api.v2.data import experimental\n",
        "with tf.device('/cpu:0'):\n",
        "  # train\n",
        "  train_data=(train_data.map(to_feature_map,\n",
        "                             num_parallel_calls=tf.data.experimental.AUTOTUNE)#determine what the no. of parallel calls should be\n",
        "  .shuffle(1000)\n",
        "  .batch(32, drop_remainder=True) #to make all batch sizes equal, put True in drop_remainder\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "\n",
        "  # valid\n",
        "  valid_data=(valid_data.map(to_feature_map,\n",
        "                             num_parallel_calls=tf.data.experimental.AUTOTUNE)#determine what the no. of parallel calls should be\n",
        "  .batch(32, drop_remainder=True) #to make all batch sizes equal, put True in drop_remainder\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLUWnfx-YDi2"
      },
      "source": [
        "The resulting `tf.data.Datasets` return `(features, labels)` pairs, as expected by [`keras.Model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Z2cy9GHQ8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b923a3-9232-481d-f1f4-efd84f9a93f1"
      },
      "source": [
        "# train data spec\n",
        "train_data.element_spec #shape = (batch size, max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGAH-ycYOmao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4abaa0e-577f-4ffc-c739-c57fa8cff9ed"
      },
      "source": [
        "# valid data spec\n",
        "valid_data.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZxe-7yhPyQe"
      },
      "source": [
        "## Task 9: Add a Classification Head to the BERT Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9THH5V0Dw2HO"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 3: BERT Layer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9il4gtlADcp"
      },
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "  input_word_ids=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,\n",
        "                                       name = 'input_word_ids')\n",
        "  input_mask=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,\n",
        "                                   name = 'input_mask'),\n",
        "  input_type_ids=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,\n",
        "                                       name='input_type_ids')\n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids,input_mask,input_type_ids])\n",
        "  drop = tf.keras.layers.Dropout(0.4)(pooled_output)\n",
        "  output = tf.keras.layers.Dense(1, activation='sigmoid', name='output')(drop)\n",
        "\n",
        "  model=tf.keras.Model(\n",
        "      inputs={\n",
        "          'input_word_ids': input_word_ids,\n",
        "          'input_mask': input_mask,\n",
        "          'input_type_ids':input_type_ids\n",
        "      },\n",
        "      outputs=output)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6maM-vr7YaJ"
      },
      "source": [
        "## Task 10: Fine-Tune BERT for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptCtiiONsBgo"
      },
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "  \n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name = 'inputs')\n",
        "\n",
        "  # preprocessing\n",
        "  preprocessor = hub.KerasLayer(tokenizer)\n",
        "  encoder_inputs = preprocessor(text_input)\n",
        "\n",
        "  # passing the encoded inputs to bert model\n",
        "  encoder = hub.KerasLayer(bert_layer, trainable=True, name = 'BERT_Encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "\n",
        "  # get the pooled outputs\n",
        "  pooled_output = outputs['pooled_output']\n",
        "\n",
        "  # add output layer\n",
        "  batch_norm = tf.keras.layers.BatchNormalization()(pooled_output)\n",
        "  drop = tf.keras.layers.Dropout(0.4)(batch_norm)\n",
        "  fc = tf.keras.layers.Dense(128, activation='relu')(drop)\n",
        "  final_output = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(fc)\n",
        "    \n",
        "  return tf.keras.Model(text_input, final_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ml06v5EQ89oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJaFnkbMtPL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14f155ff-fa43-449d-9834-851a880e7a78"
      },
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5), \n",
        "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics = [tf.keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6b65ab807f8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5), \n\u001b[1;32m      3\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               metrics = [tf.keras.metrics.BinaryAccuracy()])\n",
            "\u001b[0;32m<ipython-input-21-7fb6ba06b913>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   input_type_ids=tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,\n\u001b[1;32m      8\u001b[0m                                        name='input_type_ids')\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_word_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_type_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer\" (type KerasLayer).\n\nin user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 128) dtype=int32>, (<tf.Tensor 'inputs_1:0' shape=(None, 128) dtype=int32>,), <tf.Tensor 'inputs_2:0' shape=(None, 128) dtype=int32>]\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/1'), TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/2')]\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * [TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'), TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids')]\n        * False\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 128), dtype=int32)', ('tf.Tensor(shape=(None, 128), dtype=int32)',), 'tf.Tensor(shape=(None, 128), dtype=int32)']\n  • training=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcREcgPUHr9O"
      },
      "source": [
        "# Train model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZl1lx_cA5Y"
      },
      "source": [
        "## Task 11: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCjgrUYH_IsE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6lrFRra_KmA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opu9neBA_98R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkhtCCgnUbY6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4B8NQBLd9rN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeVNOGfFJT9O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_YWudFRJT__"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hENB__IlJUCk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkYpiGrhJUFK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYqbQZJnJUHw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiKuBGgfJUKv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}