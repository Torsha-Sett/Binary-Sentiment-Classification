{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compare-NB/LR/SCV.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeEH0rilMk1-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import fbeta_score\n",
        "from statistics import mean\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "import statistics\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvBMgv7jvIgN"
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "test_y = pd.read_csv(\"test_labels.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0freZ5JMwvB"
      },
      "source": [
        "test_labels = [\"toxic\", \"severe_toxic\", \"obscene\",\n",
        "               \"threat\", \"insult\", \"identity_hate\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBalj0r4vOMo"
      },
      "source": [
        "def tokenize(text):\n",
        "    '''\n",
        "    Tokenize text and return a non-unique list of tokenized words found in the text. \n",
        "    Normalize to lowercase, strip punctuation, remove stop words, filter non-ascii characters.\n",
        "    Lemmatize the words and lastly drop words of length < 3.\n",
        "    '''\n",
        "    text = text.lower()\n",
        "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
        "    nopunct = regex.sub(\" \", text)\n",
        "    words = nopunct.split(' ')\n",
        "    # remove any non ascii\n",
        "    words = [word.encode('ascii', 'ignore').decode('ascii') for word in words]\n",
        "    lmtzr = WordNetLemmatizer()\n",
        "    words = [lmtzr.lemmatize(w) for w in words]\n",
        "    words = [w for w in words if len(w) > 2]\n",
        "    return words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hvWnFROvSw9",
        "outputId": "26edb243-62f6-4416-c05e-28cfab3432fa"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "vector = TfidfVectorizer(ngram_range=(1, 1), analyzer='word',\n",
        "                         tokenizer=tokenize, stop_words='english',\n",
        "                         strip_accents='unicode', use_idf=1, min_df=10)\n",
        "X_train = vector.fit_transform(train['comment_text'])\n",
        "X_test = vector.transform(test['comment_text'])\n",
        "\n",
        "#word_vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode',\n",
        "   # analyzer='word',    token_pattern=r'\\w{1,}',    stop_words='english',\n",
        "   # ngram_range=(1, 1),    max_features=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3hxJrCcvhB9"
      },
      "source": [
        "# Creating classifiers with default parameters initially.\n",
        "clf1 = MultinomialNB()\n",
        "clf2 = LogisticRegression()\n",
        "clf3 = LinearSVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnMakFXlviR_"
      },
      "source": [
        "def score(classifier, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Calculate Hamming-loss, F1, Recall for each label on test dataset.\n",
        "    \"\"\"\n",
        "    methods = []\n",
        "    hloss = []\n",
        "    name = classifier.__class__.__name__.split('.')[-1]\n",
        "    predict_df = pd.DataFrame()\n",
        "    predict_df['id'] = test_y['id']\n",
        "\n",
        "    for label in test_labels:\n",
        "        classifier.fit(X_train, y_train[label])\n",
        "        predicted = classifier.predict(X_test)\n",
        "\n",
        "        predict_df[label] = predicted\n",
        "\n",
        "        recall = recall_score(y_test[y_test[label] != -1][label],\n",
        "                              predicted[y_test[label] != -1],\n",
        "                              average=\"weighted\")\n",
        "        f1 = f1_score(y_test[y_test[label] != -1][label],\n",
        "                      predicted[y_test[label] != -1],\n",
        "                      average=\"weighted\")\n",
        "\n",
        "        conf_mat = confusion_matrix(y_test[y_test[label] != -1][label],\n",
        "                                    predicted[y_test[label] != -1])\n",
        "\n",
        "        methods.append([name, label, recall, f1, conf_mat])\n",
        "\n",
        "    hamming_loss_score = hamming_loss(test_y[test_y['toxic'] != -1].iloc[:, 1:7],\n",
        "                                      predict_df[test_y['toxic'] != -1].iloc[:, 1:7])\n",
        "    hloss.append([name, hamming_loss_score])\n",
        "\n",
        "    return hloss, methods"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBt4N5hbvsHi"
      },
      "source": [
        "# Calculating the Hamming-loss F1 and Recall score for our 3 baseline models.\n",
        "h1, methods1 = score(clf1, X_train, train, X_test, test_y)\n",
        "h2, methods2 = score(clf2, X_train, train, X_test, test_y)\n",
        "h3, methods3 = score(clf3, X_train, train, X_test, test_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "MVFdHv5gvwSX",
        "outputId": "23bdd454-2193-4117-bac6-ea3496412fcf"
      },
      "source": [
        "# Creating a dataframe to show summary of results.\n",
        "methods1 = pd.DataFrame(methods1)\n",
        "methods2 = pd.DataFrame(methods2)\n",
        "methods3 = pd.DataFrame(methods3)\n",
        "methods = pd.concat([methods1, methods2, methods3])\n",
        "methods.columns = ['Model', 'Label', 'Recall', 'F1', 'Confusion_Matrix']\n",
        "meth = methods.reset_index()\n",
        "meth[['Model', 'Label', 'Recall', 'F1']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Label</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>toxic</td>\n",
              "      <td>0.935196</td>\n",
              "      <td>0.930919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>severe_toxic</td>\n",
              "      <td>0.994436</td>\n",
              "      <td>0.992145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>obscene</td>\n",
              "      <td>0.962987</td>\n",
              "      <td>0.957902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>threat</td>\n",
              "      <td>0.996702</td>\n",
              "      <td>0.995056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>insult</td>\n",
              "      <td>0.960158</td>\n",
              "      <td>0.953453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MultinomialNB</td>\n",
              "      <td>identity_hate</td>\n",
              "      <td>0.988887</td>\n",
              "      <td>0.983408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>toxic</td>\n",
              "      <td>0.935728</td>\n",
              "      <td>0.937031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>severe_toxic</td>\n",
              "      <td>0.993123</td>\n",
              "      <td>0.992762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>obscene</td>\n",
              "      <td>0.965957</td>\n",
              "      <td>0.964267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>threat</td>\n",
              "      <td>0.996530</td>\n",
              "      <td>0.995725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>insult</td>\n",
              "      <td>0.964175</td>\n",
              "      <td>0.961200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>identity_hate</td>\n",
              "      <td>0.990465</td>\n",
              "      <td>0.988378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>toxic</td>\n",
              "      <td>0.925037</td>\n",
              "      <td>0.929860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>severe_toxic</td>\n",
              "      <td>0.992982</td>\n",
              "      <td>0.992775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>obscene</td>\n",
              "      <td>0.962815</td>\n",
              "      <td>0.962684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>threat</td>\n",
              "      <td>0.996374</td>\n",
              "      <td>0.995989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>insult</td>\n",
              "      <td>0.961440</td>\n",
              "      <td>0.959917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>identity_hate</td>\n",
              "      <td>0.990497</td>\n",
              "      <td>0.989008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model          Label    Recall        F1\n",
              "0        MultinomialNB          toxic  0.935196  0.930919\n",
              "1        MultinomialNB   severe_toxic  0.994436  0.992145\n",
              "2        MultinomialNB        obscene  0.962987  0.957902\n",
              "3        MultinomialNB         threat  0.996702  0.995056\n",
              "4        MultinomialNB         insult  0.960158  0.953453\n",
              "5        MultinomialNB  identity_hate  0.988887  0.983408\n",
              "6   LogisticRegression          toxic  0.935728  0.937031\n",
              "7   LogisticRegression   severe_toxic  0.993123  0.992762\n",
              "8   LogisticRegression        obscene  0.965957  0.964267\n",
              "9   LogisticRegression         threat  0.996530  0.995725\n",
              "10  LogisticRegression         insult  0.964175  0.961200\n",
              "11  LogisticRegression  identity_hate  0.990465  0.988378\n",
              "12           LinearSVC          toxic  0.925037  0.929860\n",
              "13           LinearSVC   severe_toxic  0.992982  0.992775\n",
              "14           LinearSVC        obscene  0.962815  0.962684\n",
              "15           LinearSVC         threat  0.996374  0.995989\n",
              "16           LinearSVC         insult  0.961440  0.959917\n",
              "17           LinearSVC  identity_hate  0.990497  0.989008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PII0GbP43t25"
      },
      "source": [
        "pipe_lr = Pipeline([\n",
        "    ('lr', LogisticRegression(class_weight=\"balanced\"))\n",
        "])\n",
        "\n",
        "pipe_linear_svm = Pipeline([\n",
        "    ('svm', LinearSVC(class_weight={1: 20}))\n",
        "])\n",
        "\n",
        "pipelines = [pipe_lr, pipe_linear_svm]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPjMkC1pEIiM"
      },
      "source": [
        "score_df = []\n",
        "for pipe in pipelines:\n",
        "    f1_values = []\n",
        "    recall_values = []\n",
        "    hl = []\n",
        "    training_time = []\n",
        "    predict_df = pd.DataFrame()\n",
        "    predict_df['id'] = test_y['id']\n",
        "    for label in test_labels:\n",
        "        start = timer()\n",
        "        pipe.fit(X_train, train[label])\n",
        "        train_time = timer() - start\n",
        "        predicted = pipe.predict(X_test)\n",
        "        predict_df[label] = predicted\n",
        "\n",
        "        f1_values.append(f1_score(\n",
        "            test_y[test_y[label] != -1][label], predicted[test_y[label] != -1], average=\"weighted\"))\n",
        "        recall_values.append(recall_score(\n",
        "            test_y[test_y[label] != -1][label], predicted[test_y[label] != -1], average=\"weighted\"))\n",
        "        training_time.append(train_time)\n",
        "        name = pipe.steps[-1][1].__class__.__name__.split('.')[-1]\n",
        "\n",
        "    hamming_loss_score = hamming_loss(\n",
        "        test_y[test_y['toxic'] != -1].iloc[:, 1:7], predict_df[test_y['toxic'] != -1].iloc[:, 1:7])\n",
        "\n",
        "    val = [name, mean(f1_values), mean(recall_values),\n",
        "           hamming_loss_score, mean(training_time)]\n",
        "    score_df.append(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "wza73VyXERkV",
        "outputId": "3841761e-85e8-4a40-9abd-2b744ac24296"
      },
      "source": [
        "scores = pd.DataFrame(score_df,)\n",
        "scores.columns = ['Model', 'F1', 'Recall', 'Hamming_Loss', 'Training_Time']\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>F1</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Hamming_Loss</th>\n",
              "      <th>Training_Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.947934</td>\n",
              "      <td>0.934074</td>\n",
              "      <td>0.065926</td>\n",
              "      <td>5.598748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearSVC</td>\n",
              "      <td>0.951508</td>\n",
              "      <td>0.941634</td>\n",
              "      <td>0.058366</td>\n",
              "      <td>9.815061</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Model        F1    Recall  Hamming_Loss  Training_Time\n",
              "0  LogisticRegression  0.947934  0.934074      0.065926       5.598748\n",
              "1           LinearSVC  0.951508  0.941634      0.058366       9.815061"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV1bPWM8FKJ5",
        "outputId": "8933d7a2-e258-4850-94d6-aea44aaa3ab7"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<159571x19109 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 3510131 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    }
  ]
}